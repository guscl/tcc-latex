\chapter{Aprendizado de Máquina}


AM pode ser altamente benéfico para solução de problemas complexos, é possível observar um ciclo de trabalho bem definido que está presente na solução de problemas por uma abordagem de Aprendizado de Máquina. As etapas gerais de projetos de AM são aquisição de dados, construção de modelo, análise, otimização e predição. Com estas cinco etapas é possível sair de um conjunto de dados e chegar as respostas desejadas através de cuidadosa seleção e processamento de dados. Passando pela construção e avaliação de um método eficaz até chegar a um modelo consistente com a necessidade do problema. Embora haja uma linearidade na execução desses processos é comum em projetos de AM revisitar estas etapas várias vezes. A figura 1 revela um ciclo de AM mais detalhado e que engloba as etapas previamente citadas ressaltando elementos importantes: 

\begin{figure}[!h]
\centering
\includegraphics[keepaspectratio=true,scale=0.50]
{figuras/workflowml.eps}
\caption{Fluxo de Trabalho de AM - \cite{real2013}}
\label{workflow_am}
\end{figure}

Este capítulo serve para detalhar os processos AM. A figura anterior mostra os ciclos de trabalho que acontecem até que o modelo esteja satisfatório com as expectativas de performance. Várias etapas podem ser repetidas até que o modelo esteja refinado o suficiente. A área central que corresponde a construção do modelo pode levar várias iterações e, as vezes, é necessário rever até mesmo a primeira etapa do ciclo, Aquisição dos Dados. As próximas seções deste capítulo seguem os processos descritos no fluxo de trabalho de AM.

\begin{enumerate}
\item Aquisição dos dados
\item Engenharia de Características
\item Construção do modelo
\item Avaliação e Otimização de Modelo
\end{enumerate}

\section{Aquisição dos dados}
Apesar de parecer trivial, definir a aquisição de dados como uma etapa do projeto de AM é extremamente importante e alguns cuidados especiais devem ser considerados para que as predições tenham um bom desempenho. O primeiro passo antes de começar o projeto de AM é saber qual a necessidade do mundo real que deve ser atendida. Este passo pode ser entendido como a necessidade de encontrar questões que envolvem uma variável de interesse (quem gostaria de comprar este produto, qual o significado deste áudio em linguagem natural, onde está a face humana nesta imagem,...) e o caminho pra solução que envolve variáveis independentes (histórico de compras dos usuários, mapeamento de sons para texto, características de faces humanas).

Nem sempre utilizar Aprendizagem de Máquina é a melhor resposta para solucionar os problemas do mundo real. É necessário avaliar com cuidado quais os objetivos da solução e qual o contexto do problema. Um grande indício de que o problema pode ser solucionado por AM é se ele possui algumas das seguintes características: Alta complexidade entre entradas e saídas, grande volume de dados, necessidade de generalização e necessidade de adaptabilidade a novos cenários. 

Os dados que servem como entrada para os processos de modelagem geralmente estão apresentados na forma de tabelas que possuem colunas e linhas. As colunas representam as características dos dados, como se fossem meta-dados, e as linhas representam instâncias dessas características. A tabela a seguir representa os tipos de dados que podem aparecer como característica de dados na Aprendizagem de Máquina \cite{guy2010}.

\begin{table}[h]
\centering
\caption{Tipos de Dados}
\vspace{0.5cm}
\begin{tabular}{r|lr}

\hline 
Tipo & Exemplo  \\ % Note a separação de col. e a quebra de linhas
\hline                               % para uma linha horizontal
Átomo Categórico        & Uma palavra na língua portuguesa \\
\hline   
Átomo Numérico & Valor de temperatura \\
\hline 
Átomo Ordinário           & Preferência cinematográfica (Número de Estrelas) \\
\hline 
Conjunto desordenado de números       & Sinais vitais(pulso, temperatura, pressão sanguínea)\\
\hline 
Conjunto desordenado de misturas     & Informação demográfica(raça, sexo, idade, renda)\\
\hline 
Sequência unidimensional de categóricos       & Documento de texto\\
\hline 
Sequência unidimensional de números       & Série Temporal Financeira\\
\hline 
Sequência bidimensional de números      & Imagem\\
\hline 
Sequência tridimensional de números       & Filme\\
\hline 
Grafo Arbitrário Categórico       & Árvore de Conversões\\
 \hline 
\end{tabular}
\end{table}

A figura 2 é uma pequena seleção da base de dados que contém informações sobre os passageiros que estavam presentes no naufrágio do Titanic. 

\begin{figure}[!h]
\centering
\includegraphics[keepaspectratio=true,scale=0.40]
{figuras/dataEg.eps}
\caption{Exemplo de Dados do Titanic - \cite{titanic2012}}
\label{data_titatic}
\end{figure}

Cada linha corresponde as informações de um passageiro e cada coluna representa um tipo de informação deste passageiro. Esta base de dados foi criada com objetivo de tentar prever, através das informações de um passageiro, se ele sobreviveu ou não ao naufrágio. A base já contém a informação sobre a sobrevivência do passageiro. Muitos modelos são criados com base nas informações deste conjunto de dados, é possível fazer predições sobre a sobrevivência dos passageiros e comparar estes resultados com a informação real que já esta registrada nas tabelas. Por este motivo o conjunto de dados vem sendo usado de forma didática para AM, muitas pessoas o usam para validar seus modelos e há competições baseadas em predições com esta base \cite{titanic2011}. A enumeração a seguir explica qual o tipo de informação de cada coluna. 

\begin{enumerate}
\item IDPassageiro: Um átomo numérico que identifica unicamente cada passageiro.
\item Sobreviveu: Um átomo numérico que representa se a pessoa sobreviveu ou não ao naufrágio. Assume valor "1" para sobreviventes e "0" para não sobreviventes.
\item Pclasse: Átomo numérico que varia de "1" a "3", representa a classe do passageiro. "1" equivale a primeira classe, "2" a segunda classe e "3" a terceira.
\item Nome: Átomo categórico que representa o nome do passageiro.
\item Sexo: Átomo categórico que representa o sexo do passageiro.
\item Idade: Átomo numérico que representa a idade do passageiro.
\item IrConj: Átomo numérico que representa a soma da quantidade de irmãos e cônjuges do passageiro a bordo.
\item PaiFilh: Átomo numérico que representa a soma da quantidade de pais e filhos do passageiro a bordo.
\item Ticket: Átomo categórico que representa o número do ticket de embarque do passageiro.
\item Taixa: Átomo numérico que representa o preço da passagem paga pelo passageiro.
\item Cabine: Átomo categórico que representa o número da cabine do passageiro.
\item Embarcado: Átomo categórico que representa o porto de embarque do passageiro. "C"  para a cidade de Cherbourg, "Q"  para a cidade de Queesntown e "S"  para Southampton.
\end{enumerate}


É importante notar que nem todos os dados disponíveis são úteis para a resolução do problema. Qual seria a relevância do atributo \textbf{IDPassageiro} na resolução do problema? Este atributo é gerado automaticamente e está relacionado com a ordem dos registros no computador e não com uma característica real do passageiro. A decisão de escolher que dados são úteis para a solução do problema é um trabalho não trivial, que exige conhecimento do contexto do problema e repetidas iterações de otimização. Conhecendo o problema é possível descartar informações que não são relevantes, e tendo um modelo pronto é possível testar se determinada informação afeta ou não a performance da predição. Diminuir a quantidade de informações que entra no modelo pode ajudar no tempo em que as predições são feitas e também na performance do sistema em geral, isto se deve ao fato de que ter informações que não se relacionam com a variável de interesse aumenta o ruído do sistema, a figura 3 demonstra este fluxo de trabalho \cite{real2013}.

\begin{figure}[!h]
\centering
\includegraphics[keepaspectratio=true,scale=0.5]
{figuras/data_workflow.eps}
\caption{Fluxo de Trabalho da Seleção de Características - \cite{real2013}}
\label{workflow_data}
\end{figure}

Se houver dúvida sobre a relação causal entre determinada variável e a saída do sistema é possível realizar duas execuções do modelo: Uma com a variável independente e outra sem. Se não houver melhora na predição esse é um sinal de que a informação pode ser descartada, caso haja queda na precisão, é um indício de que a variável independente tem relação causal com a variável de interesse.

Outro fator relevante na Aquisição de Dados é que a maioria dos modelos só aceitam entradas numéricas ou categóricas. Portanto é necessário transformar outros tipos de dados em entradas ideais por um processo chamado de Engenharia de Características, este processo será descrito a frente \cite{real2013}. 

Como é possível observar na pequena seleção da base de dados do Titanic, coluna 11 (Cabine) da Figura 2, existem algumas linhas que não possuem seu valor preenchido. Esse fenômeno é chamado de Dados Faltantes, do inglês Missing Data. É comum em diversas bases de dados encontrar informações faltantes, isso se deve a diversos motivos, como erro na hora da coleta ou perdas que acontecem com o tempo. Estas informações podem ser decisivas para que o modelo aprenda algum relacionamento novo e de acordo com os autores de \citeonline{anal2003} (em livre tradução) "Um problema relevante na qualidade dos dados é a presença de dados faltantes" e " ... o tratamento de dados faltantes deve ser feito com muito cuidado, de outra forma erro pode ser introduzido no conhecimento aprendido". 

Dados faltantes podem ser encontrados por diversos motivos dentro de uma base de dados, nem todos os motivos estão relacionados a erros humanos e é importante conhecer a origem de cada tipo de dado faltante para utilizar o método de tratamento correto. A enumeração a seguir demonstra os tipos de Dados Faltantes que podem existir de acordo com \cite{stat1987}.

\begin{enumerate}
\item Missing completely at random (MCAR):Perda completamente ao acaso. É o maior nível de randomicidade. Acontece quando a probabilidade de perda em um caso pode não depender nem dos valores que esse atributo assume nem do dado perdido em si. É naturalmente randômico e qualquer método de tratamento pode ser utilizado sem o risco de introduzir erro no aprendizado.
\item Missing at random (MAR): Perda ao acaso. Quando a probabilidade de perda pode depender dos valores que atributo pode assumir, mas não pode depender do dado perdido em si.
\item Not missing at random (NMAR): Perda ao não acaso. Neste caso pode existir algum motivo real para que a instância esteja perdida. A probabilidade de perda pode depender do valor que a instância do dado assume no momento.
\end{enumerate}

Muitos métodos são propostos para lidar com este problema, ainda de acordo com  R. J. Little e D. B. Rubin apud \citeonline{anal2003}, os métodos de tratamento para dados faltantes se enquadram em uma das três categorias a seguir:

\begin{enumerate}
\item Ignorar e descartar o dado: Consiste em descartar o dados faltantes. A primeira forma de fazer isso é descartar toda a tupla que contém algum dado faltante. Outra forma é avaliar a quantidade de dados faltantes em cada tupla e em cada coluna, depois disso eliminar as instâncias(tupla ou coluna) de acordo com extensão dos dados faltantes. Antes de deletar qualquer tupla ou atributo é necessário analisar a importância desse dado na performance geral do modelo. Atributos que são relevantes devem ser mantidos mesmo se seu nível de perda for muito alto. Este método só deve ser usado quando os dados faltantes são do tipo MCAR.
\item Estimação de Parâmetro: Neste caso todas as instâncias parecidas são analisadas e o dado faltante tem seu valor atribuído com um valor que possui alta similaridade com seus vizinhos.
\item Imputação: Consiste em uma série de métodos que visam atribuir valores faltantes com estimações. Busca-se encontrar relacionamentos entre o sistema e os dados faltantes, pode-se dizer que um novo processo de AM é empregado para estimar estes valores.
\end{enumerate}


\section{Engenharia de Características}

Características englobam informações de dados brutos que habilitam algoritmos de aprendizado de máquina a classificar um objeto desconhecido ou fazer uma estimativa nova \cite{brain2013}. Características não são simplesmente conjuntos de dados, elas carregam mais informações sobre o contexto do problema. São abstrações que estruturam conjuntos de informação para que estes fiquem mais próximos a conhecimentos do mundo real.   

Engenharia de Características, EC, é o processo de transformar dados nunca trabalhados em características que melhor representam o problema atacado para o modelo preditivo, resultando em uma precisão de modelo melhorada nos dados escondidos \cite{fe2014}. Em uma outra definição, "... engenharia de características é projetar manualmente como os dados de entrada x devem ser" \cite{tomas2014}. Existem tipos de dados que precisam ser trabalhos antes de serem utilizados por modelos. Dados do tipo sequencial e do tipo categórico geralmente precisam ser tratados, pois há modelos que não estão preparados para recebe-los em sua forma inicial. Portanto, dois principais processos são feitos na base de informações inicial: análise dos dados, buscando encontrar características que não estão explícitas e transformações de dados explícitos em formatos que sejam compatíveis com o modelo escolhido. EC visa responder a pergunta: Qual a melhor forma de representar o problema pelos meus dados?

No fluxograma do começo deste capítulo, Engenharia de Características aparece como uma etapa anterior a fase de modelagem e como um processo que serve para melhorar a acurácia da modelagem. EC está no centro do Aprendizado de Máquina, pois através dela é possível entender os dados por suas características. Ela ajuda a dominar o contexto do problema, o que agrega conhecimento no modelo de AM, aumentando assim a performance das modelagens. Por esse motivo, EC aparece em vários momentos do fluxo de Aprendizado de Máquina. Inicialmente é necessário tratar os dados para começar a modelagem, e posteriormente Engenharia de Características é usada para melhorar o desempenho do modelo até que se chegue a uma precisão aceitável. 

O fluxo da Engenharia de Características é iterativo por si só. Ele consiste em construir novas características e testar o desempenho do modelo com elas. A figura 4 descreve este fluxo:


\begin{figure}[!h]
\centering
\includegraphics[keepaspectratio=true,scale=0.32]
{figuras/ecworflow.eps}
\caption{Fluxo de Trabalho de Engenharia de Características - \cite{fe2014}}
\label{workflow_ec}
\end{figure}

\begin{enumerate}
\item Brainstorm de Características: Nesta etapa um conjunto de possíveis características deve ser gerado.É necessário um aprofundamento no problema, através de meticulosa inspeção dos dados disponíveis e de experiências em casos similares. 
\item Concepção de Características: Consiste em construir características. É possível utilizar métodos automatizados de extração de características ou é possível criá-las manualmente através do conhecimento obtido na etapa anterior.
\item Seleção de Características: Nesta fase é feita uma escolha de um conjunto de características para serem testadas. É possível utilizar métodos de comparação entre as características existentes ou é possível escolher o conjunto  manualmente, de acordo com o que se conhece do problema.
\item Teste das Características: A última etapa é simples: basta introduzir as características no modelo e medir o desempenho.
\end{enumerate}

Usar Engenharia de Características sistematicamente pode aumentar a capacidade preditiva dos modelos, pois características novas são conhecimentos que poderiam não ser aprendidos naturalmente pelos algoritmos de AM. EC possibilita: Criar características que são mais relacionadas com a variável de interesse, permite a adição de informações externas relevantes dentro do modelo, habilita o uso de informações não estruturadas dentro dos modelos de AM e seleciona as características mais relevantes para a solução do problema \cite{real2013}. As próximas subseções mostram exemplos comuns de EC aplicadas no processo de AM.

\subsection{Decomposição de Atributos Categóricos}
Atributos categóricos assumem apenas um valor dentro de um conjunto de possibilidades de cada vez. Em uma tabela convencional apenas uma coluna é capaz de descrever este comportamento. Temos do exemplo do Titanic a coluna Sexo: 

\begin{figure}[!h]
\centering
\includegraphics[keepaspectratio=true,scale=0.40]
{figuras/dataEg.eps}
\caption{Exemplo de Dados do Titanic - \cite{titanic2012}}
\label{data_titatic}
\end{figure}

Cada pessoa pode ter como valor nesta coluna "male" para o sexo masculino e "female" para o sexo feminino. Muitos modelos não estão preparados para lidar com este tipo de dado. Em geral, modelos(algoritmos lineares, árvores de decisão...) precisam de informações numéricas atômicas para atuar de forma eficiente. A solução neste caso é criar mais categorias, uma coluna nova para cada valor de categoria que é possível assumir. No exemplo do Titanic é necessário abolir a coluna sexo e criar duas novas colunas: "émasculino" e "éfeminino". Estas colunas assumem um valor binário e são inversamente complementares. Isto quer dizer que se o registro diz respeito a um homem ele terá o valor "1" na coluna "émasculino" e o valor "0" na coluna "éfeminino". A mesma lógica segue para qualquer tipo de categoria, o valor positivo para a categoria desejada e o valor negativo para todas as outras possibilidades.

\subsection{Decomposição de Características}
Muitos bancos de dados possuem informação de hora em um formato de sequência de caracteres. Um exemplo de padrão desta forma é o ISO 8601, na forma: 2014-09-20T20:45:40Z. Existe muito conhecimento condensado em apenas uma sequência de letras. Através de EC é possível quebrar esta sequência em muitas outras colunas, tornando o conhecimento mais claro e aumentando a capacidade de aprendizagem do modelo. Este padrão pode ser quebrado em várias outras características, como: Ano, mês, dia, hora, minuto, segundo e turno do dia. Este método é comumente aplicado para vídeos e imagens, que são sequências de informação. Este método consiste na decomposição de uma característica complexa em várias outras mais simples.


\subsection{Características Derivadas}
Outro tipo de conhecimento que pode ser extraído vem da precisão de átomos numéricos. Em determinado banco de dados pode haver a informação da massa de um produto. Esta massa pode ser medida em várias casas decimais de gramas ou pode estar arredondada em valores inteiros de quilogramas. Ter estas informações separadas pode servir como catalisador da precisão do modelo, o processo de teste das características dirá se esta é uma boa característica ou não. Também é possível criar um atributo do tipo booliano para um limite de peso, isto é, se o produto possui mais do que cinco quilos recebe valor positivo nesta característica, se a massa for menor, recebe valor negativo.

É necessário ainda o cuidado com a seleção das características. Nem sempre uma grande quantidade de características é a melhor opção para o modelo, é  preciso selecionar os atributos mais relevantes para aumentar a acurácia da previsão. Mais características inseridas no modelo dão a capacidade de aprender novos relacionamentos. A maioria dos modelos possui uma etapa de treino, onde o conhecimento é aprendido e absorvido pelo algoritmo, e uma etapa de teste, onde o algoritmo usa o conhecimento aprendido para realizar predições no conjunto de testes. Se muitas características do conjunto de treino forem colocadas no modelo ele poderá ser incapaz de generalizar conhecimentos e atuar de forma eficaz no conjunto de testes. O nome deste fenômeno é sobre-ajustamento, do Inglês overfitting. Sobre-ajustamento gera resultados superestimados em modelos: predições que aparecem em um modelo, que é sobre-ajustado com base no conjunto de treinamento, não existem na realidade e por isso não se replicaram no conjunto de testes \cite{what2013}. A figura 6  mostra um exemplo de sobre-ajuste.

\begin{figure}[!h]
\centering
\includegraphics[keepaspectratio=true,scale=0.40]
{figuras/overfitting.eps}
\caption{Exemplo de Sobre-Ajustamento - \cite{real2013}}
\label{over}
\end{figure}

No gráfico da esquerda o modelo sobre-ajustou, aprendeu características que são exclusivas do conjunto de treinamento. Provavelmente o modelo abstraiu ruídos do aprendizado. Do lado direito há um exemplo de aprendizado correto, o treinamento serviu para aprender características do mundo real e na aplicação houve generalização correta. É por este motivo que a seleção das características ideais é tão importante,a seguir são apresentados  métodos de seleção de características.

\begin{enumerate}
\item Força Bruta: O jeito mais simples de selecionar características é simplesmente seguir o fluxo de trabalho que foi apresentado no começo deste capítulo de forma manual. Escolher um conjunto de características e testar a validade destas no modelo. Uma das vantagens dos algoritmos de AM é a capacidade de lidar com um grande número de características. O problema deste método é que fazer a seleção de um grande número de características manualmente torna-se rapidamente inviável. 
\item Algoritmos de Seleção: Existem alguns algoritmos que são capazes de relacionar características com variável de interesse. Estes modelos possuem a seleção de características incorporada em sua concepção e são capazes de escolher as características mais relevantes. Embora estes métodos não sejam aplicáveis a todos os casos, pode ser interessante usá-los como um norteador para realizar a seleção por outras vias. 
\item Adição Iterativa: Este método consiste em partir de um conjunto vazio de características e adicionar todas as características que foram levantadas de forma sistemática, de uma a uma, e testar a precisão do modelo. A parada só acontece quando todas as características foram adicionadas, ou a precisão desejada foi alcançada ou o conjunto de características chegou a um tamanho máximo pré-determinado.
\item Remoção Iterativa: Este método parte de um conjunto que contém todas as características levantas, remove uma de cada vez e a cada iteração e testa a performance do modelo. A parada só acontece quando todas as características foram removidas, ou a precisão desejada foi alcançada ou o conjunto de características chegou a um tamanho mínimo pré-determinado.
\end{enumerate}

Seleção de características pode ser usada não apenas para evitar sobre-ajustamento e deixar o modelo mais leve. É possível construir um modelo de AM apenas para chegar a etapa de seleção das características, pois nesta etapa é possível obter conhecimento valioso sobre o mundo real: Quais as características tem maior relacionamento com a variável de interesse. Apenas esse conhecimento já é suficiente para aplicar grandes mudanças no mundo real. Usando uma base que relaciona características com pacientes de câncer é possível descobrir quais as características que são mais decisivas para o desenvolvimento de um tipo de câncer \cite{real2013}.

\section{Construção do modelo}
Depois de compreender o contexto do problema e passar um tempo definindo características na base de dados é hora de construir um modelo de predição apropriado. AM busca encontrar relacionamentos e padrões que estão dentro do conjunto de dados. Através de métodos matemáticos e computacionais é possível realizar esta tarefa. O processo de descoberta dos conhecimentos ocultos nos dados é atingido através do uso do modelo. Nesta etapa de construção do modelo, é necessário aplicar o que foi descoberto sobre as características dos dados e sobre o os objetivos da solução para escolher o modelo adequado. Existem vários métodos que podem ser utilizados para revelar os relacionamentos ocultos nos dados. Os métodos podem ser simples ou complexos, indo desde de regressões lineares até redes neurais que possuem centenas de neurônios. O objetivo desta seção é descrever características de diversos tipos de modelos, a relação entre necessidades do problema e características dos modelos é que indica os possíveis métodos adequados para atingir a solução. 

A seguinte equação serve muito bem para ilustrar o objetivo de um modelo de AM: \textbf{ Y = f(X) + e}. \textbf{Y} corresponde as predições, que é o resultado final do uso do modelo. \textbf{X} corresponde a todas as entradas que são usadas no modelo, estas informações vem da base de dados e já passaram pela etapa de pré-processamento e Engenharia de Características nas fases anteriores. O conjunto \textbf{X} são os registros reais, os métodos de AM são capazes de utilizar estas informações e extrair conhecimentos relevantes para a estimação de \textbf{Y}. Estes  métodos são representados por \textbf{f(X)}, onde \textbf{f()} é a técnica de modelagem que gera as predições baseadas nas entradas do sistema. O último elemento da equação é o erro \textbf{e}. Este erro determina a precisão da predição, de forma que, se o erro chegar a 0 a precisão é total. Este erro é advindo de várias fontes, algumas delas são: Medições imperfeitas, dados faltantes e super ajustamento \cite{real2013}.

Depois de ter uma boa estimativa para a função \textbf{f(X)} é possível realizar duas tarefas distintas: predição e inferência. Predições são o resultado direto da aplicação do modelo. Quando coloca-se um novo valor de \textbf{X}, que nunca foi visto antes, como entrada do modelo, a resposta da equação é equivalente a uma predição da realidade. Inferência é algo mais profundo, é entender os motivos dos relacionamentos entre as entradas e as saídas do modelo. Como citado anteriormente, Engenharia de Características pode ser usada para realizar inferências, pois uma inferência diz o quanto uma variável relaciona-se com o resultado final \cite{real2013}. 

Existem dois tipos de modelos de Aprendizado de Máquina, paramétrico e não-paramétrico. A diferença entre eles é que os modelos paramétricos assumem que a solução possui uma forma pré-definida, isto é, estes modelos tentam descobrir o formato da função \textbf{f(X)} assumindo que ela possui um formato de curva previamente conhecido. Um modelo caracteristicamente paramétrico é a regressão linear, este método assume que a função \textbf{f(X)} é uma combinação linear do vetor de entrada, \textbf{X}, com parâmetros numéricos. Métodos não-paramétricos não fazem nenhuma pré suposição com relação ao formato geométrico da função de estimativa, estes métodos mapeiam os parâmetros de entrada às saídas. Métodos paramétricos geralmente são mais fáceis de interpretar, mas possuem performance inferior a métodos não paramétricos. Métodos não-paramétricos são difíceis de interpretar, mas são uma forma de solução mais direta e não fazem pré-suposições, que podem estar erradas \cite{on2014}.

Problemas de Aprendizado de Máquina podem cair em duas categorias: Supervisionado e Não-Supervisionado. No caso supervisionado, o modelo de AM recebe um conjunto de dados de treinamento rotulado e faz predições para pontos que não possuem rótulo. Neste caso o algoritmo utiliza o rótulo de cada entrada para refinar o aprendizado, fazendo com que as características de cada entrada sejam relacionadas com o rótulo que ela possui. No caso de aprendizado não-supervisionado, o modelo recebe apenas dados que não possuem rótulo. Neste caso, o modelo é capaz de agrupar os dados de entrada em categorias, mas ele não possui conhecimento para afirmar o que estes grupos são no mundo real \cite{foundations2012}. A vantagem da utilização de aprendizagem supervisionada é que há conhecimento extra inserido por especialistas, isto dá mais sentido aos modelos deixando claro o que cada previsão representa no mundo real. As vezes os rótulos que acompanham os dados podem estar errados, e isto aumenta o ruído do sistema. Uma das vantagens da abordagem não supervisionada é não depender de rótulos, diminuindo o erro que vem de entradas classificadas de maneira errônea. 

Existem duas principais abordagens para aprendizado não-supervisionado: agrupamento e redução de dimensionalidade. O agrupamento consiste em descobrir qual é a maneira natural que os dados de entrada se agrupam, basicamente o que o modelo faz é unir as entradas em grupos distintos de acordo com a semelhança que eles possuem entre si. A redução de dimensionalidade consiste em diminuir a complexidade das entradas. Isto é atingido quando características mais relevantes são selecionadas de acordo com a variabilidade dos dados.

Os modelos de AM realizam predições de duas formas distintas: classificação e regressão. Classificação é quando o resultado final do modelo de AM é um conjunto de saídas categóricas. Neste caso as entradas são analisadas pelo modelo e classificadas de acordo com o que foi aprendido. Um exemplo deste tipo de objetivo é o que se pode fazer com a base de dados do Titanic que foi previamente apresentada. É possível analisar as características de cada passageiro e classificá-los entre sobreviventes e mortos. Quando regressão é o objetivo final da previsão, então o modelo irá resultar em um valor contínuo. Nestes casos o aprendizado do modelo se deu na forma de uma função, e o que ele faz é  computar a entrada X para gerar uma saída Y, na forma Y = f(X) + e. 

A figura 7 lista os tipos mais comuns de algoritmos de Aprendizado de Máquina e suas características.


\begin{figure}[!h]
\centering
\includegraphics[keepaspectratio=true,scale=0.60]
{figuras/Tipos_de_Modelo.eps}
\caption{Algoritmos de AM -  \cite{real2013}}
\label{over}
\end{figure}

\section{Avaliação e Otimização de Modelo}

Encontrar uma solução para um problema através de Aprendizado de Máquina demanda tempo e algumas iterações para ajustes no modelo. É necessário construir um modelo e testar sua performance antes de começar a usá-lo no mundo real. Este capítulo consiste em métodos  de avaliação de acurácia de modelos. É necessário medir a performance dos modelos de AM para saber se se a precisão atingiu níveis aceitáveis, caso não, é necessário continuar o refinamento da modelagem até que o objetivo seja alcançado. 

O primeiro passo para resolver o problema da avaliação de performance é a definição de uma métrica que seja relevante ao método aplicado. Para controlar algo é necessário medir primeiro \cite{hjames2014}. Em uma abordagem supervisionada o objetivo desta métrica deve ser o de comparar o resultado da previsão com o valor especificado no rótulo. Em abordagens não supervisionadas, o objetivo desta métrica pode ser o de avaliar a coesão dentro e fora dos grupos criados \cite{scikit2014}. 

Para abordagens supervisionadas é possível medir a eficácia de um modelo considerando apenas as informações que entraram no sistema, isto é, avaliar se o modelo foi capaz de aprender os relacionamentos que foram apresentados. Neste caso não há preocupação com a generalização do modelo, a avaliação é feita apenas com dados que o modelo já viu e não com um conjunto novo. Este método é chamado de de Residuais. Ele consiste em utilizar o modelo para fazer previsões com os dados que foram usados para o treino, as previsões são comparadas com os rótulos que já estão associados as entradas. Se o modelo for classificador, registra-se a quantidade de entradas classificadas de forma errada e a precisão é dada pela porcentagem de erros totais. Se o modelo for um regressor, cada previsão é comparada quantitativamente com o rótulo criando-se um erro numérico. Nestes casos a métrica de qualidade é a média de todos os erros \cite{jeff1997}. 

Como já foi citado anteriormente, um problema que pode acontecer com algoritmos de AM é o sobre-ajustamento. Quando isto acontece, o modelo aprende as peculiaridades inerentes ao conjunto de treinamento tão bem que captura alguns conhecimentos que são exclusivos do conjunto de treinamento. 
Logo, o modelo absorve em sua morfologia características que não existem no mundo real e por isso terá uma precisão ruim quando apresentado a entradas que nunca foram vistas. 

Modelos de AM são treinados em um conjunto especial de dados, geralmente este conjunto é uma pequena amostra do que se encontra no mundo real. Os algoritmos de AM são capazes de aprender conhecimentos através de um conjunto de dados, o desafio é garantir que este aprendizado seja relevante para todos os dados do mundo real. Avaliar a performance de um modelo de Aprendizado de Máquina é descobrir qual a capacidade desse modelo de generalizar, ou seja, ser útil em fazer previsões quando apresentado a um conjunto de dados que nunca foi visto.

Para modelos supervisionados, buscando uma solução para o problema da medição de precisão para conjunto de dados que nunca foram vistos pelo sistema existe o método chamado de Validação Cruzada. Este método consiste em não usar todo o conjunto de treino para a construção do modelo, uma parte do conjunto é separada exclusivamente para testar a performance do modelo. Basicamente, utiliza-se a técnica de Residuais com o conjunto que foi separado especificamente para o teste. Isto evita os erros de sobre-ajustamento que seriam encontrados no método de Residuais \cite{jeff1997b}. Existem dois tipos de Validação Cruzada, Holdout e K-partes. 

O método de Validação Cruzada por Holdout, também conhecido como estimação por conjunto de teste, consiste em dividir a base de dados em dois conjuntos mutuamente excludentes chamados conjunto de treinamento e conjunto de testes, ou conjunto de holdout. É comum separar 2/3 dos dados para o conjunto de testes e 1/3 para o treinamento. O conjunto de treino é usado pelo modelo de AM para aprendizado, é deste conjunto que todo o conhecimento do modelo será retirado. Após o treinamento, o conjunto de testes é utilizado para realizar o teste do tipo Residual sobre o sistema. Quanto maior for o número de dados que são deixados para o teste menor será a capacidade de generalização do modelo, mas um conjunto de testes pequeno diminui a confiança na capacidade preditiva do modelo \cite{astudy1995}. A figura 8 demonstra o processo de holdout.

\begin{figure}[!h]
\centering
\includegraphics[keepaspectratio=true,scale=0.70]
{figuras/holdout.eps}
\caption{Crossover - Holdout - \cite{real2013}}
\label{over}
\end{figure}

Uma outra forma de fazer a validação cruzada é através do método de K-partes, também conhecido como estimação rotativa. O conjunto de dados é dividido em K partes mutuamente excludentes de tamanho aproximadamente igual. O modelo é treinado e testado k vezes. O treino é realizado com todos os sub-conjuntos menos um de cada vez. O sub-conjunto que foi deixado de fora é então utilizado como conjunto de teste. Na próxima iteração o modelo será treinado novamente e o próximo sub-conjunto será deixado de fora do treino e utilizado para a realização do teste. Todos as previsões dos testes são guardadas em um vetor e no fim de todas as iterações os rótulos são comparadas com o vetor que possui as previsões \cite{astudy1995}. Este método  é melhor para estimar o erro no conjunto real, porém é computacionalmente mais pesado e nem sempre viável. A figura 9 demostra o processo da validação cruzada utilizando k-partes.

\begin{figure}[!h]
\centering
\includegraphics[keepaspectratio=true,scale=0.60]
{figuras/kfolds.eps}
\caption{Crossover - K partes - \cite{real2013}}
\label{over}
\end{figure}

Um outro método eficaz para medição de performance é a Matriz de Confusão. Este método serve para mostrar se um algoritmo está confundindo a classificação das entradas, portanto é um método aplicável a aprendizagem supervisionada. A matriz contém informações sobre os rótulos e sobre as predições realizadas pelo modelo. A performance é medida pelas informações que estão contidas na matriz e ela pode ser usada para qualquer número de classes. A tabela a seguir mostra como funciona uma matriz de confusão para um sistema que possui apenas duas classes, negativo e positivo \cite{howard2012}. 

\begin{table}[h]
\centering
\begin{tabular}{|l|l|c|c|}
\hline
\multicolumn{2}{|l|}{\multirow{2}{*}{}}                  & \multicolumn{2}{c|}{Previsão}                                 \\ \cline{3-4} 
\multicolumn{2}{|l|}{}                                   & \multicolumn{1}{l|}{Negativo} & \multicolumn{1}{l|}{Positivo} \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{Rótulo}} & Negativo & a                             & b                             \\ \cline{2-4} 
\multicolumn{1}{|c|}{}                        & Positivo & c                             & d                             \\ \hline
\end{tabular}
\caption{Matriz de Confusão}
\label{confusion}
\end{table}

O significado de cada elemento dentro da matriz é:
\begin{enumerate}
\item \textit{a} corresponde a quantidade de predições \textbf{corretas} da classe \textbf{negativa}
\item \textit{b} corresponde a quantidade de predições \textbf{incorretas} da classe \textbf{positiva}
\item \textit{c} corresponde a quantidade de predições \textbf{incorretas} da classe \textbf{negativa}
\item \textit{d} corresponde a quantidade de predições \textbf{corretas} da classe \textbf{positiva}
\end{enumerate}

É possível retirar várias métricas desta matriz, tais como:

\begin{enumerate}
\item A acurácia (AC) é a quantidade de classificações corretas dividida por todos as possibilidades, pode ser medida através da seguinte fórmula: 
 \[
       AC =  \frac{a + d}{a + b + c + d}
  \]

\item A taxa de verdadeiro positivos (TP) é a proporção de verdadeiros positivos que foram corretamente identificados, pode ser medida por:
 \[
       TP =  \frac{d}{ c + d}
  \]

\item A taxa de falsos positivos (FP) é a proporção de falsos positivos que foram incorretamente identificados, pode ser medida por:
 \[
       FP =  \frac{b}{ a + b}
  \]
  
\item A taxa de verdadeiros negativos (VN) é a proporção de verdadeiros negativos que foram corretamente identificados, pode ser medida por:
 \[
       VN =  \frac{a}{ a + b}
  \]
  
\item A taxa de falsos negativos (FN) é a proporção de falsos negativos que foram incorretamente identificados, pode ser medida por:
 \[
       FN =  \frac{c}{c + d}
  \]

\item A precisão (P) é a proporção de casos positivos que foram corretamente classificados, pode ser calculada por:
 \[
       P =  \frac{d}{d + b}
  \] 

\end{enumerate}

É importante notar que a acurácia pode não ser uma boa métrica quando o número de casos negativos é muito maior do que o os casos positivos ou vice e versa. Neste caso, o sistema pode classificar todos os casos como pertencente a apenas uma classe, como a quantidade de casos verdadeiros desta classe é alto a acurácia será alta, porém o sistema falhou em classificar uma classe inteira! Por isso é importante observar as outras métricas em conjunto com a acurácia.

Muitos modelos de AM possuem suas saídas dadas em uma probabilidade, isto é, o modelo afirma com uma porcentagem de certeza que a entrada pertence a uma determinada classe. Existe um outro método de medir a acurácia de um modelo que encapsula todas as informações da matriz de confusão de forma gráfica e toma proveito das probabilidades das saídas.Este método é a Característica Operativa do Receptor, do Inglês Receiver Operating Characteristic (ROC). Um gráfico ROC é uma plotagem com a taxa de falsos positivos no eixo X e taxa de verdadeiros positivos no eixo Y. Os eixos representam probabilidades e vão de zero a um. O ponto (0,1) é o classificador perfeito, que é capaz de classificar corretamente todos os casos, positivos ou negativos.Uma curva ROC é capaz de mostrar a troca entre a habilidade de classificar corretamente os casos positivos e os casos negativos que são incorretamente classificados. É possível  analisar o nível de confiança do modelo de acordo com a curva. A área em baixo da curva ROC pode ser usada para medir a acurácia de vários modelos. A figura 10 é um exemplo de gráfico ROC. 
  
\begin{figure}[!h]
\centering
\includegraphics[keepaspectratio=true,scale=0.70]
{figuras/roc.eps}
\caption{Curva ROC - \cite{howard2012b}}
\label{over}
\end{figure}


Assim como na matriz de confusão, é possível analisar modelos que produzem como saída mais de uma classe. Para isto basta plotar cada par características no mesmo espaço e avaliar qual a confiança geral de acordo com a média das curvas ROC.

Para modelos que são capazes de realizar regressões não existe o conceito de predição errada ou predição certa. Para estes casos é possível analisar o quão distantes dos rótulos os valores gerados estão. Portanto, utiliza-se métodos de medição de distâncias entre pontos no espaço geométrico. O método mais simples é o cálculo da média das raízes do erro ao quadrado. Este método calcula o erro para cada uma das predições e faz uma média normalizada através da seguinte equação, yi como rótulo e f(xi) como previsão \cite{real2013}: 
 \[
       \frac{1}{\sqrt{n}}\sqrt{\sum \left [ y{i} - f\left ( x{i} \right )\right ]^{2} }
  \] 
  
Existem muitos modelos de AM que possuem um número de parâmetros que podem ser alterados, estes parâmetros são capazes de configurar diferentes comportamentos nos algoritmos e são únicos para cada contexto de uso. Existem métodos para escolher o parâmetros de forma ótima, sendo o caso mais comum a utilização de força bruta. 









































